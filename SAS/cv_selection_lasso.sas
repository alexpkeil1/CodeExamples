* cross validated selection of lasso parameter for prediction of binary variable;

*make some test data with a binary outcome;
DATA test(KEEP= c z: y);
 CALL STREAMINIT(1232224);
 ARRAY z[10];
 DO i = 1 TO 1000;
 j = 1; mu=0;
 c = RAND('table', 0.5, 0.3, 0.2)-1; *categorical variable with non-monotonic effect, 0, 1, 2;
 DO beta = 1,1,1,0,0,0,0,0,0,0;
  z[j] = RAND('normal', 0, 1);
  mu = mu + beta*Z[j];
  j = j+1;
 END;
 y = RAND('bernoulli', 1/(1+exp(-(mu  + (c=1)*2))));
 OUTPUT;
 END;
RUN;

*option 1: worst option, linear regression;
PROC GENMOD DATA = test DESC;
 CLASS C(param=ref ref='0');
 MODEL Y = Z1-z10 c / d=b link=logit;
 OUTPUT OUT=test P=p_yREG;
RUN;

*option 2: slightly better, lasso linear regression with cross validated selection of shrinkage parameter;
PROC GLMSELECT DATA = test SEED=12321;
 TITLE "10 fold cross validated linear model LASSO estimates";
 CLASS C(param=ref ref='0') / split;
 MODEL Y = Z1-z10 c / SELECTION=lasso (CHOOSE=CV STOP=CV) CVMETHOD=RANDOM(10)  DETAILS=ALL CVDETAILS=ALL;
 OUTPUT OUT=test(RENAME=(p_y=p_yLASSO));
RUN;

*option 3: much better, lasso logistic regression with AIC selection of shrinkage parameter;
*this one is probably what you want - selection of the parameter by AIC will be almost as good as
 k-fold cross validation;
PROC HPGENSELECT DATA=TEST; 
   TITLE "non-cross validated lasso estimates in logistic model";
   CLASS C(ref='0') / split;
   MODEL Y(EVENT='1') = Z1-z10 c / DIST=BINARY LINK=LOGIT;
   SELECTION METHOD=lasso(CHOOSE=BIC STOP=BIC);
   OUTPUT OUT = TEST p = p_yhpLASSOnocv; *model predictions;
   ID _ALL_;
RUN;;

*option 4: best option, lasso logistic regression with AIC selection of shrinkage parameter;
*this will take tweaking, and so may not be ideal for sanity's sake; 
%MACRO CVLASSO(data=test, sampsize = 200, NFOLDS=5, rhovals=%str(0.1 .4));
*1) modifying for k-fold cross validation;
  * summary: create variables cvfold1-cvfoldk for k folds that = 0 if the data are 'training' data and 1 if the data 
  * are 'testing' data;
DATA testmod;
 *first ensure data are sorted randomly;
 SET &data;
 __srt = _N_;
 CALL STREAMINIT(123211);
 __rsrt = RAND('uniform');
PROC SORT DATA = testmod; BY __rsrt;
DATA testmod;
 SET testmod;
 ARRAY cvfold[&nfolds];
 DO k = 1 TO &nfolds;
  cvfold[k]=0;
 END;
 DO k = 1 TO &nfolds;
  IF FLOOR((&sampsize/&nfolds)*(k-1))<=_N_< FLOOR(&sampsize/&nfolds)*(k) THEN cvfold[k]=1 ;
 END;
 *assign for last observation;
 IF _N_ = FLOOR(&sampsize/&nfolds)*(&nfolds)  THEN cvfold[&nfolds]=1;
 RUN;
 *run model for each value of the shrinkage parameter, rho;
 ODS LISTING CLOSE;
 %LET r = 1;
 %DO %WHILE(%TRIM(%SCAN(&RHOVALS, &R,  %str( )))~=);
  %LET rho = %SCAN(&RHOVALS, &R,%str( ));
  * run model for each fold;
  %LET k=1;
  %DO %WHILE(%EVAL(&k<=&nfolds));
  PROC HPGENSELECT DATA=TESTmod LASSORHO=&rho LASSOSTEPS=1; 
    TITLE "hpgenselect";
    CLASS C(ref='0') / split;
    PARTITION ROLE=cvfold&k (TRAIN='0' VALID='1');
    MODEL Y(EVENT='1') = Z1-z10 c / DIST=BINARY LINK=LOGIT;
    SELECTION METHOD=lasso;
    OUTPUT OUT = TESTmod p = PLfold_&r._&k;
    ID _ALL_;
    ODS OUTPUT parameterestimates=parmcv_&r._&k;
  RUN;;
  PROC SORT DATA = parmcv_&r._&k;  BY effect parameter;
%LET k=%EVAL(&K+1);
%END;
* get cross validation parameter estimates for each value of rho;
DATA lassoparms_&r;
 MERGE 
 %LET k=1;
  %DO %WHILE(%EVAL(&k<=&nfolds)); 
   parmcv_&r._&k (RENAME=(estimate=est_fold&k))
  %LET k=%EVAL(&K+1);
 %END;
; BY effect parameter;
 ARRAY est_fold[&nfolds];
 estimate=0;
 DO k = 1 TO &nfolds;
  IF est_fold[k] <= .z THEN est_fold[k] = 0;
  estimate = estimate + est_fold[k]/&nfolds;
 END;

*get cross validated predictions for each value of rho;
DATA testmod;* (DROP plfold:);
 SET testmod;
 ARRAY cvfold[&nfolds];
 ARRAY plfold_&r._[&nfolds];
 plcv_&R = 0;
 DO k = 1 TO &nfolds;
   plcv_&R = plcv_&R + cvfold[k]*plfold_&r._[k];
 END;
 sqerrcv_&r = (plcv_&R-y)**2; *get squared error of estimate (use this as a selection criterion for rho parameter);
%LET r=%EVAL(&r+1);
%END;
ODS LISTING;
RUN;
PROC MEANS DATA = testmod MEAN;
 TITLE 'select the model with the lowest cross validated mean squared error';
 VAR sqerrcv_:;
RUN;
*resort data in original order;
PROC SORT DATA = TESTMOD OUT= &data(DROP=SQERRCV_: plfold_: cvfold: k);
 BY __srt;
RUN;
*do some cleanup of the work directory;
PROC DATASETS LIBRARY=WORK; delete parmcv:;quit;
%MEND;
OPTIONS MPRINT;
%CVLASSO(data=test, sampsize = 1000, NFOLDS=5, rhovals=%str(0.001 0.005 0.01 0.05 0.1 0.2));
OPTIONS NOMPRINT;
*Then just use the predictions from the LASSO model that gives the lowest mse;
DATA test;
 SET test;
 p_yhpLASSOcv = plcv_3;
PROC PRINT DATA = lassoparms_3;
 TITLE 'cross validated parameter estimates';
 VAR effect parameter estimate est_:;
RUN;

  PROC HPGENSELECT DATA=TEST LASSORHO=.01 LASSOSTEPS=1; 
    TITLE "hpgenselect";
    CLASS C(ref='0') / split;
    MODEL Y(EVENT='1') = Z1-z10 c / DIST=BINARY LINK=LOGIT;
    SELECTION METHOD=lasso;
    OUTPUT OUT = TEST p = p_yhpLASSOcv2;
    ID _ALL_;
  RUN;;



DATA test; 
 SET test;
 sqerr_hplassocv = (p_yhpLASSOcv-y)**2;
 sqerr_hplassocv2 = (p_yhpLASSOcv2-y)**2;
 sqerr_hplassonocv = (p_yhpLASSOnocv-y)**2;
 sqerr_lasso = (p_ylasso-y)**2;
 sqerr_reg = (p_yreg-y)**2;

PROC MEANS DATA = test;
 TITLE 'mean squared error of each prediction algorithm';
 * note, the non cv lasso will likely have a better looking mean squared error as a result of overfit;
 VAR y p_y: sqerr:;
RUN;
